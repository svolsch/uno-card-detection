{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uno Card Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is an implementation of a computer vision algorithm for detecting Uno cards in a video stream and on individual images using Python and OpenCV. \n",
    "\n",
    "The algorithm first extracts features and color information from each frame of the video stream, and then uses a pre-trained Random Forest Classifier to predict the type of the card. \n",
    "\n",
    "The predicted card type is displayed on the video stream in real-time using OpenCV. \n",
    "\n",
    "The code allows for the detection of specific types of Uno cards: \"Number Cards\", \"Pick Two,\" \"Reverse,\" and \"Skip\" \n",
    "\n",
    "The code can be easily adapted to detect other types of cards or objects by training a new classifier on a diverse and large dataset.\n",
    "\n",
    "Below are the blocks of code that I used to build this project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Extraction\n",
    "For extracting the color of the card we first select the region of onterest and crop the rest of the image. \n",
    "\n",
    "After that I have used pre-defined HSV ranges for blue, red, green and yellow color to create a bitwise and mask to select specific colors in the card. \n",
    "After applying the mask I check for the maximum pixels of the color that remained after applying the mask and then classify the color of the card. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np   \n",
    " # Extracting color of the card\n",
    "img_colour = cv2.imread('./unocards/ys.jpg')   # open the saved image in colour\n",
    "\n",
    "img = cv2.cvtColor(img_colour, cv2.COLOR_BGR2GRAY)   # convert to B/W\n",
    "img_HSV = cv2.cvtColor(img_colour, cv2.COLOR_BGR2HSV) # Convert to HSV\n",
    "img_sm = cv2.blur(img, (7, 7))         # smoothing\n",
    "thr_value, img_th = cv2.threshold(img_sm, 160, 255, cv2.THRESH_BINARY_INV)   # binarisation\n",
    "\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "img_close = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)      # morphology correction\n",
    "img_canny = cv2.Canny(img_close, 100, 200)                          # edge detection\n",
    "contours, hierarchy = cv2.findContours(img_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)   # extract contours on binarised image, not on canny\n",
    "\n",
    "# Select the region of interest i.e the card and crop the background \n",
    "contour1 = contours[1]\n",
    "x, y, w, h = cv2.boundingRect(contour1) # Find the bounding rectangle of contour 1\n",
    "\n",
    "crop_img = img_colour[y:y+h, x:x+w] # Crop the image to the bounding rectangle\n",
    "\n",
    "# Checking for color using HSV ranges\n",
    "\n",
    "# Convert the image to HSV\n",
    "hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the range of colors for the Uno card\n",
    "\n",
    "# Green color range\n",
    "green_lower = np.array([36, 25, 25])\n",
    "green_upper = np.array([65, 255, 255])\n",
    "# Yellow color range\n",
    "y_lower = np.array([15, 50, 50])  \n",
    "y_upper = np.array([30, 255, 255])\n",
    "\n",
    "# Blue color range\n",
    "blue_lower = np.array([100, 150, 150])\n",
    "blue_upper = np.array([130, 255, 255])\n",
    "\n",
    "# Red color range (two ranges to account for hue wraparound)\n",
    "red_lower1 = np.array([0, 50, 50])\n",
    "red_upper1 = np.array([10, 255, 255])\n",
    "\n",
    "# Create a mask for the red color\n",
    "mask_yellow = cv2.inRange(hsv, y_lower, y_upper)\n",
    "mask_red = cv2.inRange(hsv, red_lower1, red_upper1)\n",
    "mask_green = cv2.inRange(hsv, green_lower, green_upper)\n",
    "mask_blue = cv2.inRange(hsv, blue_lower, blue_upper)\n",
    "# Bitwise-AND mask and original image\n",
    "res_y = cv2.bitwise_and(crop_img,crop_img, mask= mask_yellow)\n",
    "res_r = cv2.bitwise_and(crop_img,crop_img, mask= mask_red)\n",
    "res_g = cv2.bitwise_and(crop_img,crop_img, mask= mask_green)\n",
    "res_b = cv2.bitwise_and(crop_img,crop_img, mask= mask_blue)\n",
    "\n",
    "# Check if the card is red, yellow , blue or green\n",
    "counts = [np.count_nonzero(res_r), np.count_nonzero(res_y), np.count_nonzero(res_g), np.count_nonzero(res_b)]\n",
    "colors = [0,1,2,3] # Red = 0, yellow = 1, green = 2, blue = 3\n",
    "\n",
    "if max(counts) == 0:\n",
    "    print(\"Card Color not recognized\")\n",
    "else:\n",
    "    color_index = counts.index(max(counts))\n",
    "    color = colors[color_index]\n",
    "\n",
    "print(color)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Features and creating a Dataset of features\n",
    "\n",
    "In this code I get the contours of the card and select a particular contour that I am interested in i.e the contour of the number or the type of the card inside the ellipse. \n",
    "\n",
    "I select the contour by using the heirarchy retrived by the RETR_TREE method in OpenCV. The images I have used in this project only contain the uno card on a black background. If there is any noise in the images the features extractin will fail as it'll be difficult to reach to the contour of the number of the card inside the ellipse. \n",
    "\n",
    "After selecting all the child contours of the ellipse I merge them into a single conotur and apply feature extraction operations on it. \n",
    "\n",
    "The feature that I extract from the merged contour are: Aspect Ratio, Extent, Solidity, Equivalent Diameter, Hu Moments and the number of holes.\n",
    "\n",
    "After extracting the contours I loop through all the images in the dataset, extract the features from each image and save the features with the card type as the classes using joblib. \n",
    "\n",
    "The dataset is similar to the iris dataset in structure i.e it contains a dictionary of arrays of features and classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset_final.joblib']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "\n",
    "def feature_extract(image_path):\n",
    "\n",
    "    img_colour = cv2.imread(image_path)\n",
    "\n",
    "    img_gray = cv2.cvtColor(img_colour, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, img_th = cv2.threshold(img_gray, 160, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_close = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(img_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Create a list to store the areas of each contour\n",
    "    areas = []\n",
    "\n",
    "    # Iterate over the contours and calculate the area of each contour\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        areas.append(area)\n",
    "\n",
    "    # Use the numpy.argsort() function to get the indices of the areas in descending order\n",
    "    sorted_areas_indices = np.argsort(-np.array(areas))\n",
    "\n",
    "    # Select the third largest contour and its children\n",
    "    third_largest_contour_index = sorted_areas_indices[2]\n",
    "\n",
    "    # Define a recursive function to find all the children of a given contour index\n",
    "    def find_children_indices(hierarchy, index):\n",
    "        children_indices = []\n",
    "        child_index = hierarchy[0][index][2]\n",
    "        while child_index != -1:\n",
    "            children_indices.append(child_index)\n",
    "            grandchild_indices = find_children_indices(hierarchy, child_index)\n",
    "            children_indices.extend(grandchild_indices)\n",
    "            child_index = hierarchy[0][child_index][0]\n",
    "        return children_indices\n",
    "\n",
    "    children_indices = find_children_indices(hierarchy, third_largest_contour_index)\n",
    "\n",
    "    # Merge the contours of the children of the third largest contour into a single variable for feature extraction\n",
    "    merged_contour = None\n",
    "    for child_index in children_indices:\n",
    "        if merged_contour is None:\n",
    "            merged_contour = contours[child_index]\n",
    "        else:\n",
    "            merged_contour = np.concatenate((merged_contour, contours[child_index]))\n",
    "\n",
    "\n",
    "    \n",
    "    # Aspect Ratio\n",
    "    x,y,w,h = cv2.boundingRect(merged_contour)\n",
    "    aspect_ratio = float(w)/h\n",
    "\n",
    "    # Extent\n",
    "    contour_area = cv2.contourArea(merged_contour)\n",
    "    x, y, w, h = cv2.boundingRect(merged_contour)\n",
    "    rect_area = w*h # Area for the bounding rectangle\n",
    "    extent = float(contour_area)/rect_area\n",
    "\n",
    "    # Solidity\n",
    "    area = cv2.contourArea(merged_contour)\n",
    "    hull = cv2.convexHull(merged_contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    solidity = float(area) / hull_area\n",
    "\n",
    "    # Equivalent Diameter \n",
    "    area = cv2.contourArea(merged_contour)\n",
    "    equi_diameter = np.sqrt(4*area/np.pi)\n",
    "\n",
    "    #Hu Moments \n",
    "    moments = cv2.moments(merged_contour)\n",
    "    hu_moments = cv2.HuMoments(moments)\n",
    "\n",
    "    # Convert the Hu moments into logscale\n",
    "    hu_moments_log = -1 * cv2.log(abs(hu_moments))\n",
    "\n",
    "    # Assign the transformed Hu moments to variables\n",
    "    h1 = hu_moments_log[0][0]\n",
    "    h2 = hu_moments_log[1][0]\n",
    "    h3 = hu_moments_log[2][0]\n",
    "    h4 = hu_moments_log[3][0]\n",
    "    h5 = hu_moments_log[4][0]\n",
    "    h6 = hu_moments_log[5][0]\n",
    "    h7 = hu_moments_log[6][0]\n",
    "\n",
    "    #Finding number of holes \n",
    "    x, y, w, h = cv2.boundingRect(merged_contour) # Find the bounding rectangle of contour 1\n",
    "\n",
    "    crop_img = img_colour[y:y+h, x:x+w] # Crop the image to the bounding rectangle\n",
    "    img_gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, img_th = cv2.threshold(img_gray, 160, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_close = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(img_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    # Create a list to store the areas of each contour\n",
    "    areas = []\n",
    "\n",
    "    # Iterate over the contours and calculate the area of each contour\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        areas.append(area)\n",
    "\n",
    "    # Use the numpy.argsort() function to get the indices of the areas in descending order\n",
    "    sorted_areas_indices = np.argsort(-np.array(areas))\n",
    "\n",
    "    # Select the second largest contour and its children\n",
    "    num_contour_index = sorted_areas_indices[1]\n",
    "    second_largest_contour = contours[num_contour_index]\n",
    "    num_holes = 0\n",
    "\n",
    "    # Iterate over the hierarchy to count the number of child contours\n",
    "    if hierarchy.size > 0:\n",
    "        hierarchy = hierarchy[0]\n",
    "        current_contour = hierarchy[num_contour_index][2]\n",
    "        while current_contour != -1:\n",
    "            num_holes += 1\n",
    "            current_contour = hierarchy[current_contour][0]\n",
    "\n",
    "    return [aspect_ratio, extent, solidity, equi_diameter, num_holes, h1, h2, h3, h4, h5, h6, h7]\n",
    "\n",
    "\n",
    "# Create empty lists to store the six features and labels\n",
    "features = []\n",
    "labels = []\n",
    "images_folder = './unocards/'\n",
    "# Loop through each image and extract the six features from its contour\n",
    "for image_file in os.listdir(images_folder):\n",
    "    image_path = os.path.join(images_folder, image_file)\n",
    "    feature_set = feature_extract(image_path)\n",
    "    features.append(feature_set)\n",
    "    match = re.search(r'\\d+', image_file)\n",
    "    if match:\n",
    "        file_num = int(match.group())\n",
    "    labels.append(file_num)\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "    # labels = np.append(labels, int(os.path.splitext(image_file[1:])[0]))\n",
    "joblib.dump([{'data': features, 'target' : labels}], 'dataset_final.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unodata = joblib.load(\"dataset_final.joblib\")\n",
    "# print(unodata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Random Forest Classifier on the created Dataset\n",
    "\n",
    "I have used Random Forest Classifier for this problem because it performs really well on the problems with multiple classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uno_rfc.joblib']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = unodata[0]['data']\n",
    "y = unodata[0]['target']\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "joblib.dump(rfc, \"uno_rfc.joblib\")    # save the model after training, remember the file name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Got an accuracy on 90% on the dataset when performed a 80 - 20 Train - Test Split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "rfc = joblib.load(\"uno_rfc.joblib\")    # load the model to test it\n",
    "score = rfc.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def feature_extract(image_path):\n",
    "    # Image Pre-processing\n",
    "    img_colour = cv2.imread(image_path)\n",
    "\n",
    "    img_gray = cv2.cvtColor(img_colour, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, img_th = cv2.threshold(img_gray, 160, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_close = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(img_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Create a list to store the areas of each contour\n",
    "    areas = []\n",
    "\n",
    "    # Iterate over the contours and calculate the area of each contour\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        areas.append(area)\n",
    "\n",
    "    # Use the numpy.argsort() function to get the indices of the areas in descending order\n",
    "    sorted_areas_indices = np.argsort(-np.array(areas))\n",
    "\n",
    "    # Select the third largest contour and its children\n",
    "    third_largest_contour_index = sorted_areas_indices[2]\n",
    "\n",
    "    # Define a recursive function to find all the children of a given contour index\n",
    "    def find_children_indices(hierarchy, index):\n",
    "        children_indices = []\n",
    "        child_index = hierarchy[0][index][2]\n",
    "        while child_index != -1:\n",
    "            children_indices.append(child_index)\n",
    "            grandchild_indices = find_children_indices(hierarchy, child_index)\n",
    "            children_indices.extend(grandchild_indices)\n",
    "            child_index = hierarchy[0][child_index][0]\n",
    "        return children_indices\n",
    "\n",
    "    children_indices = find_children_indices(hierarchy, third_largest_contour_index)\n",
    "\n",
    "    # Merge the contours of the children of the third largest contour into a single variable for feature extraction\n",
    "    merged_contour = None\n",
    "    for child_index in children_indices:\n",
    "        if merged_contour is None:\n",
    "            merged_contour = contours[child_index]\n",
    "        else:\n",
    "            merged_contour = np.concatenate((merged_contour, contours[child_index]))\n",
    "\n",
    "\n",
    "    \n",
    "    # Aspect Ratio\n",
    "    x,y,w,h = cv2.boundingRect(merged_contour)\n",
    "    aspect_ratio = float(w)/h\n",
    "\n",
    "    # Extent\n",
    "    contour_area = cv2.contourArea(merged_contour)\n",
    "    x, y, w, h = cv2.boundingRect(merged_contour)\n",
    "    rect_area = w*h # Area for the bounding rectangle\n",
    "    extent = float(contour_area)/rect_area\n",
    "\n",
    "    # Solidity\n",
    "    area = cv2.contourArea(merged_contour)\n",
    "    hull = cv2.convexHull(merged_contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    solidity = float(area) / hull_area\n",
    "\n",
    "    # Equivalent Diameter \n",
    "    area = cv2.contourArea(merged_contour)\n",
    "    equi_diameter = np.sqrt(4*area/np.pi)\n",
    "\n",
    "    #Hu Moments \n",
    "    moments = cv2.moments(merged_contour)\n",
    "    hu_moments = cv2.HuMoments(moments)\n",
    "\n",
    "    # Convert the Hu moments into logscale\n",
    "    hu_moments_log = -1 * cv2.log(abs(hu_moments))\n",
    "\n",
    "    # Assign the transformed Hu moments to variables\n",
    "    h1 = hu_moments_log[0][0]\n",
    "    h2 = hu_moments_log[1][0]\n",
    "    h3 = hu_moments_log[2][0]\n",
    "    h4 = hu_moments_log[3][0]\n",
    "    h5 = hu_moments_log[4][0]\n",
    "    h6 = hu_moments_log[5][0]\n",
    "    h7 = hu_moments_log[6][0]\n",
    "\n",
    "    #Finding number of holes \n",
    "    x, y, w, h = cv2.boundingRect(merged_contour) # Find the bounding rectangle of contour 1\n",
    "\n",
    "    crop_img = img_colour[y:y+h, x:x+w] # Crop the image to the bounding rectangle\n",
    "    img_gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, img_th = cv2.threshold(img_gray, 160, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_close = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(img_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    # Create a list to store the areas of each contour\n",
    "    areas = []\n",
    "\n",
    "    # Iterate over the contours and calculate the area of each contour\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        areas.append(area)\n",
    "\n",
    "    # Use the numpy.argsort() function to get the indices of the areas in descending order\n",
    "    sorted_areas_indices = np.argsort(-np.array(areas))\n",
    "\n",
    "    # Select the second largest contour and its children\n",
    "    num_contour_index = sorted_areas_indices[1]\n",
    "    second_largest_contour = contours[num_contour_index]\n",
    "    num_holes = 0\n",
    "\n",
    "    # Iterate over the hierarchy to count the number of child contours\n",
    "    if hierarchy.size > 0:\n",
    "        hierarchy = hierarchy[0]\n",
    "        current_contour = hierarchy[num_contour_index][2]\n",
    "        while current_contour != -1:\n",
    "            num_holes += 1\n",
    "            current_contour = hierarchy[current_contour][0]\n",
    "    return [aspect_ratio, extent, solidity, equi_diameter, num_holes, h1, h2, h3, h4, h5, h6, h7]\n",
    "\n",
    "def color_extract(image_path):\n",
    "    img_colour = cv2.imread(image_path)   # open the saved image in colour\n",
    "\n",
    "    # Image Pre-processing\n",
    "    img = cv2.cvtColor(img_colour, cv2.COLOR_BGR2GRAY)   # convert to B/W\n",
    "    img_HSV = cv2.cvtColor(img_colour, cv2.COLOR_BGR2HSV) # Convert to HSV\n",
    "    img_sm = cv2.blur(img, (7, 7))         # smoothing\n",
    "    thr_value, img_th = cv2.threshold(img_sm, 160, 255, cv2.THRESH_BINARY_INV)   # binarisation\n",
    "    # img_th = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 35, 2)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_close = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)      # morphology correction\n",
    "    img_canny = cv2.Canny(img_close, 100, 200)                          # edge detection\n",
    "    contours, hierarchy = cv2.findContours(img_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)   # extract contours on binarised image, not on canny\n",
    "\n",
    "    # Select the region of interest i.e the card and crop the background \n",
    "    contour1 = contours[1]\n",
    "    x, y, w, h = cv2.boundingRect(contour1) # Find the bounding rectangle of contour 1\n",
    "\n",
    "    crop_img = img_colour[y:y+h, x:x+w] # Crop the image to the bounding rectangle\n",
    "\n",
    "    # Checking for color using HSV ranges\n",
    "\n",
    "    # Convert the image to HSV\n",
    "    hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the range of colors for the Uno card\n",
    "\n",
    "    # Green color range\n",
    "    green_lower = np.array([36, 25, 25])\n",
    "    green_upper = np.array([65, 255, 255])\n",
    "    green_range = np.array([green_lower, green_upper])\n",
    "\n",
    "    # Yellow color range\n",
    "    y_lower = np.array([15, 50, 50])  \n",
    "    y_upper = np.array([30, 255, 255])\n",
    "    yellow_range = np.array([y_lower, y_upper])\n",
    "\n",
    "    # Blue color range\n",
    "    blue_lower = np.array([100, 150, 150])\n",
    "    blue_upper = np.array([130, 255, 255])\n",
    "    blue_range = np.array([blue_lower, blue_upper])\n",
    "\n",
    "    # Red color range (two ranges to account for hue wraparound)\n",
    "    red_lower1 = np.array([0, 50, 50])\n",
    "    red_upper1 = np.array([10, 255, 255])\n",
    "    red_lower2 = np.array([170, 50, 50])\n",
    "    red_upper2 = np.array([180, 255, 255])\n",
    "    red_range = np.array([red_lower1, red_upper1, red_lower2, red_upper2])\n",
    "\n",
    "    # Create a mask for the red color\n",
    "    mask_yellow = cv2.inRange(hsv, y_lower, y_upper)\n",
    "    mask_red = cv2.inRange(hsv, red_lower1, red_upper1)\n",
    "    mask_green = cv2.inRange(hsv, green_lower, green_upper)\n",
    "    mask_blue = cv2.inRange(hsv, blue_lower, blue_upper)\n",
    "    # Bitwise-AND mask and original image\n",
    "    res_y = cv2.bitwise_and(crop_img,crop_img, mask= mask_yellow)\n",
    "    res_r = cv2.bitwise_and(crop_img,crop_img, mask= mask_red)\n",
    "    res_g = cv2.bitwise_and(crop_img,crop_img, mask= mask_green)\n",
    "    res_b = cv2.bitwise_and(crop_img,crop_img, mask= mask_blue)\n",
    "\n",
    "    # Check if the card is red, yellow , blue or green\n",
    "    counts = [np.count_nonzero(res_r), np.count_nonzero(res_y), np.count_nonzero(res_g), np.count_nonzero(res_b)]\n",
    "    colors = [\"RED\", \"YELLOW\", \"GREEN\", \"BLUE\"]\n",
    "\n",
    "    if max(counts) == 0:\n",
    "        print(\"Card Color not recognized\")\n",
    "    else:\n",
    "        color_index = counts.index(max(counts))\n",
    "        det_color = colors[color_index]\n",
    "    return det_color"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YELLOW [0]\n"
     ]
    }
   ],
   "source": [
    "feat = []\n",
    "image_path = './uno_images_test/y0.jpg'\n",
    "fx = feature_extract(image_path)\n",
    "col = color_extract(image_path)\n",
    "feat.append(fx)\n",
    "feat = np.array(feat)\n",
    "rfc = joblib.load(\"uno_rfc.joblib\") \n",
    "predict = rfc.predict(feat)\n",
    "if predict == np.array([100]): # Pick two card is labeled as 100 in the dataset\n",
    "    predict = 'Pick Two'\n",
    "elif predict == np.array([200]): # Reverse card is labeled as 100 in the dataset\n",
    "    predict = 'Reverse'\n",
    "elif predict == np.array([300]): # Skip card is labeled as 100 in the dataset\n",
    "    predict = 'Skip'\n",
    "print(col, predict)\n",
    "# print(type(predict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Camera stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def feature_extract(frame):\n",
    "    img_colour = frame\n",
    "    img_gray = cv2.cvtColor(img_colour, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_th = cv2.threshold(img_gray, 160, 255, cv2.THRESH_BINARY_INV)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_close = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, hierarchy = cv2.findContours(img_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    # Create a list to store the areas of each contour\n",
    "    areas = []\n",
    "    # Iterate over the contours and calculate the area of each contour\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        areas.append(area)\n",
    "    # Use the numpy.argsort() function to get the indices of the areas in descending order\n",
    "    sorted_areas_indices = np.argsort(-np.array(areas))\n",
    "    # Select the third largest contour and its children\n",
    "    third_largest_contour_index = sorted_areas_indices[2]\n",
    "    # Define a recursive function to find all the children of a given contour index\n",
    "    def find_children_indices(hierarchy, index):\n",
    "        children_indices = []\n",
    "        child_index = hierarchy[0][index][2]\n",
    "        while child_index != -1:\n",
    "            children_indices.append(child_index)\n",
    "            grandchild_indices = find_children_indices(hierarchy, child_index)\n",
    "            children_indices.extend(grandchild_indices)\n",
    "            child_index = hierarchy[0][child_index][0]\n",
    "        return children_indices\n",
    "    children_indices = find_children_indices(hierarchy, third_largest_contour_index)\n",
    "    # Merge the contours of the children of the third largest contour into a single variable for feature extraction\n",
    "    merged_contour = None\n",
    "    for child_index in children_indices:\n",
    "        if merged_contour is None:\n",
    "            merged_contour = contours[child_index]\n",
    "        else:\n",
    "            merged_contour = np.concatenate((merged_contour, contours[child_index]))\n",
    "    # Aspect Ratio\n",
    "    x,y,w,h = cv2.boundingRect(merged_contour)  \n",
    "    aspect_ratio = float(w)/h\n",
    "    # Extent\n",
    "    contour_area = cv2.contourArea(merged_contour)\n",
    "    x, y, w, h = cv2.boundingRect(merged_contour)\n",
    "    rect_area = w*h # Area for the bounding rectangle\n",
    "    extent = float(contour_area)/rect_area\n",
    "    # Solidity\n",
    "    area = cv2.contourArea(merged_contour)\n",
    "    hull = cv2.convexHull(merged_contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    solidity = float(area) / hull_area\n",
    "    # Equivalent Diameter \n",
    "    area = cv2.contourArea(merged_contour)\n",
    "    equi_diameter = np.sqrt(4*area/np.pi)\n",
    "    #Hu Moments \n",
    "    moments = cv2.moments(merged_contour)\n",
    "    hu_moments = cv2.HuMoments(moments)\n",
    "    # Convert the Hu moments into logscale\n",
    "    hu_moments_log = -1 * cv2.log(abs(hu_moments))\n",
    "    # Assign the transformed Hu moments to variables\n",
    "    h1 = hu_moments_log[0][0]\n",
    "    h2 = hu_moments_log[1][0]\n",
    "    h3 = hu_moments_log[2][0]\n",
    "    h4 = hu_moments_log[3][0]\n",
    "    h5 = hu_moments_log[4][0]\n",
    "    h6 = hu_moments_log[5][0]\n",
    "    h7 = hu_moments_log[6][0]\n",
    "\n",
    "    #Finding number of holes \n",
    "    x, y, w, h = cv2.boundingRect(merged_contour) # Find the bounding rectangle of contour 1\n",
    "        \n",
    "    crop_img = img_colour[y:y+h, x:x+w] # Crop the image to the bounding rectangle\n",
    "            \n",
    "    img_gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, img_th = cv2.threshold(img_gray, 160, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_close = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(img_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    # Create a list to store the areas of each contour\n",
    "    areas = []\n",
    "\n",
    "    # Iterate over the contours and calculate the area of each contour\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        areas.append(area)\n",
    "\n",
    "    # Use the numpy.argsort() function to get the indices of the areas in descending order\n",
    "    sorted_areas_indices = np.argsort(-np.array(areas))\n",
    "\n",
    "    # Select the second largest contour and its children\n",
    "    num_contour_index = sorted_areas_indices[1]\n",
    "    second_largest_contour = contours[num_contour_index]\n",
    "    num_holes = 0\n",
    "\n",
    "    # Iterate over the hierarchy to count the number of child contours\n",
    "    if hierarchy.size > 0:\n",
    "        hierarchy = hierarchy[0]\n",
    "        current_contour = hierarchy[num_contour_index][2]\n",
    "        while current_contour != -1:\n",
    "            num_holes += 1\n",
    "            current_contour = hierarchy[current_contour][0]\n",
    "    return [aspect_ratio, extent, solidity, equi_diameter, num_holes, h1, h2, h3, h4, h5, h6, h7]\n",
    "       \n",
    "\n",
    "def color_extract(frame):\n",
    "    img_colour = frame\n",
    "\n",
    "    # Image Pre-processing\n",
    "    img = cv2.cvtColor(img_colour, cv2.COLOR_BGR2GRAY)   # convert to B/W\n",
    "    img_HSV = cv2.cvtColor(img_colour, cv2.COLOR_BGR2HSV) # Convert to HSV\n",
    "    img_sm = cv2.blur(img, (7, 7))         # smoothing\n",
    "    thr_value, img_th = cv2.threshold(img_sm, 160, 255, cv2.THRESH_BINARY_INV)   # binarisation\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_close = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)      # morphology correction\n",
    "    img_canny = cv2.Canny(img_close, 100, 200)                          # edge detection\n",
    "    contours, hierarchy = cv2.findContours(img_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)   # extract contours on binarised image, not on canny\n",
    "\n",
    "    # Select the region of interest i.e the card and crop the background \n",
    "    contour1 = contours[1]\n",
    "    x, y, w, h = cv2.boundingRect(contour1) # Find the bounding rectangle of contour 1\n",
    "\n",
    "    crop_img = img_colour[y:y+h, x:x+w] # Crop the image to the bounding rectangle\n",
    "\n",
    "    # Checking for color using HSV ranges\n",
    "\n",
    "    # Convert the image to HSV\n",
    "    hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the range of colors for the Uno card\n",
    "\n",
    "    # Green color range\n",
    "    green_lower = np.array([36, 25, 25])\n",
    "    green_upper = np.array([65, 255, 255])\n",
    "    green_range = np.array([green_lower, green_upper])\n",
    "\n",
    "    # Yellow color range\n",
    "    y_lower = np.array([15, 50, 50])  \n",
    "    y_upper = np.array([30, 255, 255])\n",
    "    yellow_range = np.array([y_lower, y_upper])\n",
    "\n",
    "    # Blue color range\n",
    "    blue_lower = np.array([100, 150, 150])\n",
    "    blue_upper = np.array([130, 255, 255])\n",
    "    blue_range = np.array([blue_lower, blue_upper])\n",
    "\n",
    "    # Red color range (two ranges to account for hue wraparound)\n",
    "    red_lower1 = np.array([0, 50, 50])\n",
    "    red_upper1 = np.array([10, 255, 255])\n",
    "    red_lower2 = np.array([170, 50, 50])\n",
    "    red_upper2 = np.array([180, 255, 255])\n",
    "    red_range = np.array([red_lower1, red_upper1, red_lower2, red_upper2])\n",
    "\n",
    "    # Create a mask for the red color\n",
    "    mask_yellow = cv2.inRange(hsv, y_lower, y_upper)\n",
    "    mask_red = cv2.inRange(hsv, red_lower1, red_upper1)\n",
    "    mask_green = cv2.inRange(hsv, green_lower, green_upper)\n",
    "    mask_blue = cv2.inRange(hsv, blue_lower, blue_upper)\n",
    "    # Bitwise-AND mask and original image\n",
    "    res_y = cv2.bitwise_and(crop_img,crop_img, mask= mask_yellow)\n",
    "    res_r = cv2.bitwise_and(crop_img,crop_img, mask= mask_red)\n",
    "    res_g = cv2.bitwise_and(crop_img,crop_img, mask= mask_green)\n",
    "    res_b = cv2.bitwise_and(crop_img,crop_img, mask= mask_blue)\n",
    "\n",
    "    # Check if the card is red, yellow , blue or green\n",
    "    counts = [np.count_nonzero(res_r), np.count_nonzero(res_y), np.count_nonzero(res_g), np.count_nonzero(res_b)]\n",
    "    colors = [\"RED\", \"YELLOW\", \"GREEN\", \"BLUE\"]\n",
    "\n",
    "    if max(counts) == 0:\n",
    "        det_color = \"Not Recognised\"\n",
    "    else:\n",
    "        color_index = counts.index(max(counts))\n",
    "        det_color = colors[color_index]\n",
    "    return det_color    \n",
    "\n",
    "vc = cv2.VideoCapture(1) \n",
    "while vc.isOpened():\n",
    "    rval, frame = vc.read()    # read video frames again at each loop, as long as the stream is open\n",
    "    feat = []\n",
    "    try:\n",
    "        fx = feature_extract(frame)\n",
    "        col = color_extract(frame)\n",
    "        feat.append(fx)\n",
    "        feat = np.array(feat)\n",
    "        rfc = joblib.load(\"uno_rfc.joblib\") \n",
    "        predict = rfc.predict(feat)\n",
    "        if predict == np.array([100]): # Pick two card is labeled as 100 in the dataset\n",
    "            predict = 'Pick Two'\n",
    "        elif predict == np.array([200]): # Reverse card is labeled as 100 in the dataset\n",
    "            predict = 'Reverse'\n",
    "        elif predict == np.array([300]): # Skip card is labeled as 100 in the dataset\n",
    "            predict = 'Skip'\n",
    "        card_type = [col, predict]\n",
    "        cv2.putText(frame, str(card_type), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    except:\n",
    "        pass\n",
    "    cv2.imshow(\"stream\", frame)# display each frame as an image, \"stream\" is the name of the window\n",
    "    key = cv2.waitKey(1)       # allows user intervention without stopping the stream (pause in ms)\n",
    "    if key == 27:              # exit on ESC\n",
    "        break\n",
    "    \n",
    "cv2.destroyWindow(\"stream\")    # close image window upon exit\n",
    "vc.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scripts used for capturing images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For number cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vc = cv2.VideoCapture(1)\n",
    "img_count = 0\n",
    "special_cards = ['skip', 'reverse','picktwo']\n",
    "while vc.isOpened():\n",
    "    rval, frame = vc.read()    # read video frames again at each loop, as long as the stream is open\n",
    "    cv2.imshow(\"stream\", frame)# display each frame as an image, \"stream\" is the name of the window\n",
    "    key = cv2.waitKey(1)       # allows user intervention without stopping the stream (pause in ms)\n",
    "    if key == 32:\n",
    "        img_name = \"./unocards/g{}.jpg\".format(img_count)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        img_count += 1\n",
    "    elif key == 27:              # exit on ESC\n",
    "        break\n",
    "cv2.destroyWindow(\"stream\")    # close image window upon exit\n",
    "vc.release()   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Pick Two, Reverse and Skip Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vc = cv2.VideoCapture(1)\n",
    "img_count = 0\n",
    "i = 0\n",
    "special_cards = ['skip', 'reverse','picktwo']\n",
    "wild_cards = ['pickfour', 'colorswitch']\n",
    "\n",
    "while vc.isOpened():\n",
    "    rval, frame = vc.read()    # read video frames again at each loop, as long as the stream is open\n",
    "    cv2.imshow(\"stream\", frame)# display each frame as an image, \"stream\" is the name of the window\n",
    "    key = cv2.waitKey(1)       # allows user intervention without stopping the stream (pause in ms)\n",
    "    if key == 32:\n",
    "            img_name = \"./unocards/{}.jpg\".format(wild_cards[i])\n",
    "            i+=1\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            \n",
    "    elif key == 27:              # exit on ESC\n",
    "        break\n",
    "cv2.destroyWindow(\"stream\")    # close image window upon exit\n",
    "vc.release()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
